# ğŸš€HLFS: Enabling Long-term Memory to Forget like human

This is the official repository for the paper "HLFS: Enabling Long-term Memory to Forget like human". 
In this paper, we introduce the **Human-Like Forgetting System (HLFS)**, a comprehensive forgetting system based on a variant of the Ebbinghaus forgetting curve. Building upon this, we have developed the **General Chat Box (GCB)**. The overall architecture of the model is illustrated in the following diagram:

<img src="misc/workflow.png" align="middle" width="95%">

#  âœ¨ Updates
- [**2024-06-08**] We have established an open-source repository for **HLFS** for the first time

# ğŸŒ Overview
HLFS is a comprehensive forgetting system with a range of functions including memory storage, data backup and recovery, and a recall mechanism. Powered by HLFS, GCB integrates gpt-3.5-turbo and boasts excellent dialogue processing capabilities.

The detailed project structure tree is as follows:

```markdown
HLFS/
â”œâ”€â”€ box/ -- GCB
â”‚   â”œâ”€â”€ box_demo.py
â”‚   â””â”€â”€ box_functions.py 
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ forget/ -- Forgetting curve
â”‚   â”œâ”€â”€ retrieve/ -- Memory retrieve methods
â”‚   â”‚   â”œâ”€â”€ con_sim.py
â”‚   â”‚   â””â”€â”€ faiss.py
â”‚   â””â”€â”€ mem_struct.py -- Data structure for HLFS and GCB
â”‚
â”œâ”€â”€ data/ -- Datasets
â”‚
â”œâ”€â”€ eval/
â”‚   â”œâ”€â”€ data/ -- Datasets of the critical dialogue retention=30%, 56%, 82%
â”‚   â”‚   â”œâ”€â”€ retention_30
â”‚   â”‚   â”œâ”€â”€ retention_56
â”‚   â”‚   â””â”€â”€ retention_82
â”‚   â”œâ”€â”€ image/ -- Results
â”‚   â”œâ”€â”€ cal_metrics.py -- Benchmark
â”‚   â”œâ”€â”€ cal_sim.py -- Similarity calculation
â”‚   â”œâ”€â”€ curve.py -- Curve plotting
â”‚   â””â”€â”€ data_loader.py -- Loading the construction dataset
â”‚
â”œâ”€â”€ history/ -- Memory storage
â”‚   â””â”€â”€ bake/ -- Dataset of Retention=100%
â”‚  
â”œâ”€â”€ logs/
â”‚
â”œâ”€â”€ misc/ 
â”‚
â”œâ”€â”€ prompts/ 
â”‚   â””â”€â”€ prompts.py -- The prompts and correlation functions
â”‚
â”œâ”€â”€ utils/ 
â”‚   â”œâ”€â”€ api.py
â”‚   â”œâ”€â”€ log.py
â”‚   â””â”€â”€ tools.py
â”‚
â”œâ”€â”€ requirements.txt
â”‚
â””â”€â”€ README.md
â”‚
â””â”€â”€ second_derivative_integral.py -- Calculation of second derivative integration in the appendix
```
# ğŸ‘¨â€ğŸ’» Usage

## config

In `config/config.py`, Contains parameters related to HLFS and GCB. In addition, you need to put all your apiKeys into `openai_key` (especially if your apiKeys are restricted)

## Requirements

The key requirements are as below:

- python 3.9+
- openai 0.27.0+
- llama-index==0.5.17.post1
- transformers==4.28.0

## Installation

Step 1: Create a new conda environment:
```shell
conda create -n hlfs python=3.9 -y
conda activate hlfs
```

Step 2: Install relevant packages
```shell
pip install -r requirements.txt
```

## Run

We strive to make the process of experiencing the code as simple as possible.

### Construction Dataset
We provide a method for loading and constructing datasets, which is in `eval/data_loader.py`, You can change variable `data_dir` and `data_file` to select one.

But we have already helped complete this step, The constructed datasets under different retention rates are as follows:

- _R_=100%: `history/bake/`
- _R_=82%: `eval/data/retention_82`
- _R_=56%: `eval/data/retention_56`
- _R_=30%: `eval/data/retention_30`

you can directly transfer the constructed dataset to `history/` so that GCB can read directly from it:
```shell
mv history/bake/en/exercise/* history/
```
or:
```shell
mv eval/data/retention_82/en/exercise/* history/
```

### Dialogue with GCB
You can run this command to directly communicate with GCB:
```shell
cd box/
python box_demo.py \
    --language en \
    --history_path ../history \
    --test_model False \
    --ltm_box hlfs
```

We provide a quick overview of the arguments:

- `--language`: Choose language`['cn', 'en']`
- `--history_path`: Set the location for saving conversation history, user information, etc. **We strongly recommend that you keep the default** `../history`
- `--test_model`: Test mode, if you want to use the dataset provided in our paper for result validation, please set it to `True`. In this case, the Global Memory Table (GMT) will not be updated and your conversation process will not be saved. If you want to experience the complete GCB conversation service, please set it to `False`. You will experience the full functionality. 
- `--ltm_box`: We inherited two benchmarks`['hlfs', 'scm']`. For MemoryBank, please visit [MemoryBank-SiliconFriend](https://github.com/zhongwanjun/MemoryBank-SiliconFriend)

âš ï¸ Please note that dialogue with GCB does not require `/history` to be non-empty.

### Periodic trigger forgetting
```shell
cd core/
python timer.py \
    --test_model False \
    --time_gap 1 \
    --recall_times 1 \
    --forgetting_cycle 1 
```
Here:
- `--test_model`: If `True`, you need to set `--time_gap` and `--recall_times` by yourself; if `False`, you need to set `--forgetting_cycle`
- `--time_gap`: The time gap between the last recall and the present (test_model = True)
- `--recall_times`: recall times (test_model = True)
- `--forgetting_cycle`

âš ï¸ Please note that Periodic trigger forgetting does require /history to be non-empty.

### Evaluation stage
-`eval/cal_metrics.py`: Benchmark comparative experiment

-`eval/cal_sim.py`: Contextual Coherence, Topic Similarity.

-`second_derivative_integral.py`: Calculate the second derivative integral, as detailed in the appendix of the paper

ğŸ“ˆ We have already run the program in advance and all the results have been accurately labeled in the dataset, Please refer to the code for specific usage details

# License

This project is released under the MIT license. Please see the [LICENSE](LICENSE) file for more information.